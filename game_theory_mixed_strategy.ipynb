{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1. -1.]\n",
      "  [-1.  1.]]\n",
      "\n",
      " [[-1.  1.]\n",
      "  [ 1. -1.]]]\n",
      "Strategy:  [[0.50038111, 0.49961888790130615], [0.50038111, 0.49961888790130615]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def game_theory_mixed_strategy(p_table):\n",
    "    ### payoff table\n",
    "    #### A's        B's strategy\n",
    "    ####      L          R\n",
    "    #### U  (1, 1)     (0, 0)\n",
    "    #### D  (0, 0)     (1, 1)\n",
    "    payoff_table = tf.constant(p_table)\n",
    "    \n",
    "    #### A's U strategy = p and D's R strategy = (1 - p)\n",
    "    #### B's L strategy = q and B's R strategy = (1 - q)\n",
    "    pv = tf.Variable(1., dtype=tf.float32)\n",
    "    qv = tf.Variable(1., dtype=tf.float32)\n",
    "    \n",
    "    #### Defined p and q scale (0, 1)\n",
    "    p = tf.sigmoid(pv)\n",
    "    q = tf.sigmoid(qv)\n",
    "    \n",
    "    a_strategy = tf.transpose([p, 1 - p])\n",
    "    b_strategy = tf.transpose([q, 1 - q])\n",
    "    \n",
    "    a_u = tf.reshape(tf.slice(payoff_table, [0, 0, 0], [1, 2, 1]), \n",
    "                    [-1])\n",
    "    a_d = tf.reshape(tf.slice(payoff_table, [1, 0, 0], [1, 2, 1]),\n",
    "                    [-1])\n",
    "    \n",
    "    b_l = tf.reshape(tf.slice(payoff_table, [0, 0, 1], [2, 1, 1]),\n",
    "                    [-1])\n",
    "    b_r = tf.reshape(tf.slice(payoff_table, [0, 1, 1], [2, 1, 1]),\n",
    "                    [-1])\n",
    "    a_u_result = tf.reduce_sum(tf.multiply(a_u, a_strategy))\n",
    "    a_d_result = tf.reduce_sum(tf.multiply(a_d, a_strategy))\n",
    "    a_loss = tf.square(a_u_result - a_d_result)\n",
    "    a_opt = tf.train.AdamOptimizer(0.2).minimize(a_loss)\n",
    "    \n",
    "    b_l_result = tf.reduce_sum(tf.multiply(b_l, b_strategy))\n",
    "    b_r_result = tf.reduce_sum(tf.multiply(b_r, b_strategy))\n",
    "    b_loss = tf.square(b_l_result - b_r_result)\n",
    "    b_opt = tf.train.AdamOptimizer(0.2).minimize(b_loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print (sess.run(payoff_table))\n",
    "        _p = 0\n",
    "        _q = 0\n",
    "        for i in range(100):\n",
    "            _, _p, _l = sess.run([a_opt, p, a_loss])\n",
    "            _, _q, _l = sess.run([b_opt, q, b_loss])\n",
    "        return _p, _q\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    pt = [\n",
    "        [[1., -1.], [-1., 1.]],\n",
    "        [[-1., 1.], [1., -1.]]\n",
    "    ]\n",
    "    p, q = game_theory_mixed_strategy(pt)\n",
    "    print ('Strategy: ', [[p, 1-p], [q, 1-q]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
